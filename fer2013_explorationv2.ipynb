{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import random_split\n",
    "from torchvision import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(r\"C:\\Users\\bches\\Classes\\Spring_2021\\Pattern_Recognition\\Project\\datasets\\FER2013\\train\\X_train.npy\")\n",
    "y_train = np.load(r\"C:\\Users\\bches\\Classes\\Spring_2021\\Pattern_Recognition\\Project\\datasets\\FER2013\\train\\y_train.npy\")\n",
    "X_val = np.load(r\"C:\\Users\\bches\\Classes\\Spring_2021\\Pattern_Recognition\\Project\\datasets\\FER2013\\train\\X_val.npy\")\n",
    "y_val = np.load(r\"C:\\Users\\bches\\Classes\\Spring_2021\\Pattern_Recognition\\Project\\datasets\\FER2013\\train\\y_val.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22967, 48, 48),\n",
       " (22967,),\n",
       " (5742, 48, 48),\n",
       " (5742,),\n",
       " (array([0, 1, 2, 3, 4, 5, 6]),\n",
       "  array([3187,  345, 3265, 5783, 3927, 3887, 2573], dtype=int64)),\n",
       " (array([0, 1, 2, 3, 4, 5, 6]),\n",
       "  array([ 808,   91,  832, 1432, 1038,  943,  598], dtype=int64)))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape, np.unique(y_train, return_counts=True), np.unique(y_val, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1efa90486a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[50], cmap = 'gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([22967, 48, 48]),\n",
       " <function Tensor.type>,\n",
       " torch.Size([22967]),\n",
       " torch.Size([5742, 48, 48]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert data from numpy to tensors\n",
    "X_train_t = torch.tensor(X_train.tolist(), dtype=torch.float32)/255\n",
    "y_train_t = torch.tensor(y_train.tolist(), dtype=torch.long)\n",
    "X_val_t = torch.tensor(X_val.tolist(), dtype=torch.float32)/255\n",
    "y_val_t = torch.tensor(y_val.tolist(), dtype=torch.long)\n",
    "\n",
    "\n",
    "X_train_t.type(torch.float32)\n",
    "y_train_t.type(torch.float32)\n",
    "X_val_t.type(torch.float32)\n",
    "y_val_t.type(torch.float32)\n",
    "\n",
    "X_train_t.shape, X_train_t.type, y_train_t.shape, X_val_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([22967, 1, 48, 48]),\n",
       " torch.Size([5742, 1, 48, 48]),\n",
       " <function Tensor.type>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pytorch tensors require N X C X H X W \n",
    "X_train_t = X_train_t.unsqueeze(1).contiguous()\n",
    "X_val_t = X_val_t.unsqueeze(1).contiguous()\n",
    "\n",
    "X_train_t.shape, X_val_t.shape, y_train_t[0].type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([22967]), tensor([2, 3, 3,  ..., 3, 5, 0]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_t.shape, y_train_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.),\n",
       " tensor(1.),\n",
       " tensor(0.),\n",
       " tensor(1.),\n",
       " tensor(0),\n",
       " tensor(6),\n",
       " tensor(0),\n",
       " tensor(6))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_t.min(), X_train_t.max(), X_val_t.min(), X_val_t.max(), y_train_t.min(), y_train_t.max(), y_val_t.min(), y_val_t.max() #double check to make sure min is 0 and max is 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.5076]), tensor([0.2548]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_t.view(1,-1).mean(dim=1), X_train_t.view(1,-1).std(dim=1) #check mean and std deviation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5076]) tensor([0.2548])\n"
     ]
    }
   ],
   "source": [
    "train_mean = X_train_t.view(1,-1).mean(dim=1)\n",
    "train_std = X_train_t.view(1,-1).std(dim=1)\n",
    "\n",
    "\n",
    "print(train_mean, train_std)\n",
    "\n",
    "val_mean = X_val_t.view(1,-1).mean(dim=1)\n",
    "val_std = X_val_t.view(1,-1).std(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = torchvision.transforms.Compose([\n",
    "            #torchvision.ToPILImage(), #need this to do data augmentation, only accepts PIL images\n",
    "            #torchvision.transforms.Resize(48), #48 is FER2013 size\n",
    "            #torchvision.transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=train_mean, std=train_std)\n",
    "])\n",
    "\n",
    "val_transform = torchvision.transforms.Compose([\n",
    "            #torchvision.ToPILImage(), #need this to do data augmentation, only accepts PIL images\n",
    "            #torchvision.transforms.Resize(48), #48 is FER2013 size\n",
    "            #torchvision.transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=train_mean, std=train_std)\n",
    "])\n",
    "\n",
    "val_transform_test = torchvision.transforms.Compose([\n",
    "            #torchvision.ToPILImage(), #need this to do data augmentation, only accepts PIL images\n",
    "            #torchvision.transforms.Resize(48), #48 is FER2013 size\n",
    "            #torchvision.transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=val_mean, std=val_std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data set class definition\n",
    "\n",
    "class my_dataset(Dataset):\n",
    "    def __init__(self, X, y, transform = None):\n",
    "        self.data = X\n",
    "        self.target = y\n",
    "        self.transform = transform\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            print(\"Data placed in GPU memory\")\n",
    "            self.data = self.data.cuda()\n",
    "            self.target = self.target.cuda()\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            return x.cuda(), y.cuda()\n",
    "        \n",
    "        return x,y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "\n",
    "class baseline_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        self.device = torch.device(\"cuda\" if self.use_cuda else \"cpu\")\n",
    "        print(\"model device:\", self.device)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size = 3, padding = 1) \n",
    "        self.conv2 = nn.Conv2d(10, 32, kernel_size = 3, padding = 1) \n",
    "\n",
    "        self.fc1 = nn.Linear(32*12*12, 100)\n",
    "\n",
    "        self.fc2 = nn.Linear(100, num_classes) \n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(F.relu(self.conv1(x)), kernel_size=2) #kernel of 2 for max pool\n",
    "        out = F.max_pool2d(F.relu(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 32*12*12)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "\n",
    "class baseline_net_dp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        self.device = torch.device(\"cuda\" if self.use_cuda else \"cpu\")\n",
    "        print(\"model device:\", self.device)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size = 3, padding = 1) \n",
    "        self.dp1 = nn.Dropout2d(p=0.4)\n",
    "        self.conv2 = nn.Conv2d(10, 32, kernel_size = 3, padding = 1) \n",
    "        self.dp2 = nn.Dropout2d(p=0.4)\n",
    "        self.fc1 = nn.Linear(32*12*12, 100)\n",
    "\n",
    "        self.fc2 = nn.Linear(100, num_classes) \n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(F.relu(self.conv1(x)), kernel_size=2) #kernel of 2 for max pool\n",
    "        out = self.dp1(out)\n",
    "        out = F.max_pool2d(F.relu(self.conv2(out)), 2)\n",
    "        out = self.dp2(out)\n",
    "        out = out.view(-1, 32*12*12)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "\n",
    "class baseline_net_deep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        self.device = torch.device(\"cuda\" if self.use_cuda else \"cpu\")\n",
    "        print(\"model device:\", self.device)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size = 3, padding = 1) \n",
    "        self.dp1 = nn.Dropout2d(p=0.4)\n",
    "        self.conv2 = nn.Conv2d(10, 32, kernel_size = 3, padding = 1) \n",
    "        self.dp2 = nn.Dropout2d(p=0.4)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size = 3, padding = 1) \n",
    "        self.dp3 = nn.Dropout2d(p=0.4)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size = 3, padding = 1) \n",
    "        self.dp4 = nn.Dropout2d(p=0.4)\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(128*3*3, 100)\n",
    "\n",
    "        self.fc2 = nn.Linear(100, num_classes) \n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(F.relu(self.conv1(x)), kernel_size=2) #kernel of 2 for max pool\n",
    "        out = self.dp1(out)\n",
    "        out = F.max_pool2d(F.relu(self.conv2(out)), 2)\n",
    "        out = self.dp2(out)\n",
    "        out = F.max_pool2d(F.relu(self.conv3(out)), kernel_size=2) #kernel of 2 for max pool\n",
    "        out = self.dp3(out)\n",
    "        out = F.max_pool2d(F.relu(self.conv4(out)), 2)\n",
    "        out = self.dp4(out)\n",
    "        out = out.view(-1, 128*3*3)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "\n",
    "class baseline_net_bn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        self.device = torch.device(\"cuda\" if self.use_cuda else \"cpu\")\n",
    "        print(\"model device:\", self.device)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size = 3, padding = 1) \n",
    "        self.bn1 = nn.BatchNorm2d(num_features = 10)\n",
    "        self.conv2 = nn.Conv2d(10, 32, kernel_size = 3, padding = 1) \n",
    "        self.bn2 = nn.BatchNorm2d(num_features = 32)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size = 3, padding = 1) \n",
    "        self.bn3 = nn.BatchNorm2d(num_features = 64)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size = 3, padding = 1)         \n",
    "        self.bn4 = nn.BatchNorm2d(num_features = 128)\n",
    "\n",
    "        self.fc1 = nn.Linear(128*3*3, 100)\n",
    "\n",
    "        self.fc2 = nn.Linear(100, num_classes) \n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.bn1(self.conv1(x))\n",
    "        out = F.max_pool2d(F.relu(out), kernel_size=2) #kernel of 2 for max pool\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = F.max_pool2d(F.relu(out), 2)\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out = F.max_pool2d(F.relu(out), kernel_size=2) #kernel of 2 for max pool\n",
    "        out = self.bn4(self.conv4(out))\n",
    "        out = F.max_pool2d(F.relu(out), 2)\n",
    "        out = out.view(-1, 128*3*3)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors = []\n",
    "val_errors = []\n",
    "#val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = 32, shuffle=True)\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader, val_loader):\n",
    "    patience = 50 #50 epoch patience for early stopping\n",
    "    if model.use_cuda:\n",
    "      if(torch.cuda.device_count() > 1):\n",
    "        print(\"Using data parallel for training model\")\n",
    "        model = nn.DataParallel(model)\n",
    "      model = model.to(model.device)\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        \n",
    "        loss_train = 0.0\n",
    "        val_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        model.train()\n",
    "        for imgs, labels in train_loader:\n",
    "            #print(imgs.shape, labels.shape)\n",
    "            #print(imgs)\n",
    "            outputs = model(imgs)\n",
    "            #print(outputs, labels)\n",
    "\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_train += loss.item()\n",
    "            #print(outputs)\n",
    "            _, pred1 = torch.max(outputs, dim=1)\n",
    "            #print(pred1)\n",
    "            #print(torch.max(outputs,dim=1))\n",
    "            total_train += labels.shape[0]\n",
    "            correct_train += (pred1==labels).sum()\n",
    "            #train_acc = 100*correct_train/total_train\n",
    "            \n",
    "        train_errors.append(loss_train)\n",
    "        \n",
    "        total = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for imgs1, label in val_loader:\n",
    "                outputs1 = model(imgs1)\n",
    "                #print(outputs1)\n",
    "                _, pred = torch.max(outputs1, dim=1)\n",
    "                total += label.shape[0]\n",
    "                correct += (pred == label).sum()\n",
    "                val_loss += loss_fn(outputs1, label)\n",
    "                val_errors.append(val_loss)\n",
    "        #print(\"Validation accuracy: \", 100*correct/total)\n",
    "        \n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "              print('{} Epoch {}, Training loss {}, Training accuracy {} Validation accuracy {}'.format(datetime.datetime.now(), epoch, float(loss_train), float(100*correct_train/total_train), float(100*correct/total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data placed in GPU memory\n",
      "Data placed in GPU memory\n"
     ]
    }
   ],
   "source": [
    "train_dataset = my_dataset(X_train_t, y_train_t, transform=train_transform)\n",
    "\n",
    "val_dataset = my_dataset(X_val_t, y_val_t, transform=val_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taken from Haotians Lenet code, cite this if submitting it\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Conv2d:\n",
    "        nn.init.orthogonal_(m.weight)\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.orthogonal_(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "211839"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "model = baseline_net_bn()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "baseline_net_bn(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(10, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=1152, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(init_weights) #initialize weights to have orthogonal projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-21 11:30:03.361785 Epoch 1, Training loss 334.8934953212738, Training accuracy 26.163625717163086 Validation accuracy 31.34796142578125\n",
      "2021-04-21 11:32:00.312691 Epoch 10, Training loss 115.4477832019329, Training accuracy 76.66216278076172 Validation accuracy 54.022987365722656\n",
      "2021-04-21 11:34:11.071577 Epoch 20, Training loss 26.107586156576872, Training accuracy 95.03199768066406 Validation accuracy 54.26680374145508\n"
     ]
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs = 20, \n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    "    val_loader = val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data placed in GPU memory\n",
      "2021-04-21 11:35:52.472308 Epoch 1, Training loss 27.210413344204426, Training accuracy 94.81864929199219 Validation accuracy 52.17694091796875\n",
      "2021-04-21 11:37:47.618337 Epoch 10, Training loss 14.955113135278225, Training accuracy 97.31352996826172 Validation accuracy 53.74433898925781\n",
      "2021-04-21 11:39:57.173332 Epoch 20, Training loss 11.369155581342056, Training accuracy 97.97534942626953 Validation accuracy 53.06513214111328\n"
     ]
    }
   ],
   "source": [
    "val_dataset_test = my_dataset(X_val_t, y_val_t, transform=val_transform_test)\n",
    "val_loader_test = torch.utils.data.DataLoader(val_dataset_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 20, \n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    "    val_loader = val_loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
